{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ED18B034_EE4703_A3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB8wJx3YYWeR"
      },
      "source": [
        "# Classifying the Car Evaluation Dataset Using a Decision Tree Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CuJjOT4YgY9"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx3xE8sOM89B"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install -U imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTEN\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, plot_confusion_matrix, roc_auc_score\n",
        "\n",
        "!pip install dtreeviz\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "import graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NU1cVhEYiTs"
      },
      "source": [
        "## Utility functions, for data visualzation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffMlOj_QUlxo"
      },
      "source": [
        "# Plotting the distribution of all features\n",
        "def plot_dist(data):\n",
        "  print (\"Number of data points = \", data.shape[0])\n",
        "  print (\"Distribution of data points:\")\n",
        "  rows = int(np.ceil(data.shape[1]/4))\n",
        "  fig, ax = plt.subplots(rows, 4, figsize = (12,rows*3))\n",
        "  i = 0\n",
        "  j = 0\n",
        "  for column in data:\n",
        "    data[column].value_counts().plot.pie(ax=ax[i][j])\n",
        "    if j<3:\n",
        "      j += 1\n",
        "    else:\n",
        "      i += 1\n",
        "      j = 0\n",
        "  while j<=3:\n",
        "    ax[i][j].set_axis_off()\n",
        "    j+=1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bHlef61Yosy"
      },
      "source": [
        "## Importing the data, data cleaning, augmentation, and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkRAVeEsRa6v"
      },
      "source": [
        "data = pd.read_csv(\"car_evaluation.csv\")\n",
        "data.columns=[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\", \"target\"]\n",
        "\n",
        "# Preliminary data analytics\n",
        "plot_dist(data)\n",
        "\n",
        "X = data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y = data[\"target\"]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "# Over Sampling data using SMOTE\n",
        "sm = SMOTEN(random_state=42)\n",
        "X_aug, Y_aug = sm.fit_resample(X_train, Y_train)\n",
        "aug_data = pd.concat([X_aug, Y_aug], axis=1)\n",
        "test_data = pd.concat([X_test, Y_test], axis=1)\n",
        "\n",
        "# Data Analytics for Over Sampled Data\n",
        "plot_dist(aug_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vxYw7qCuuE2"
      },
      "source": [
        "# Plotting each feature wrt the target variable\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"buying\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"buying\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"maint\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"maint\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"doors\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"doors\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"persons\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"persons\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"lug_boot\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"lug_boot\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,3))\n",
        "sns.histplot(x=\"safety\", hue=\"target\", data=data, multiple=\"dodge\", palette=\"pastel\", ax=ax[0]);\n",
        "sns.histplot(x=\"safety\", hue=\"target\", data=aug_data, multiple=\"dodge\", palette=\"pastel\", ax=ax[1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW2zptTA69ZE"
      },
      "source": [
        "# Converting to encoder variables\n",
        "for column in aug_data:\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(aug_data[column])\n",
        "  aug_data[column] = encoder.transform(aug_data[column])\n",
        "  test_data[column] = encoder.transform(test_data[column])\n",
        "  print (\"\\n\", column,\":\")\n",
        "  if column==\"persons\" or column==\"lug_boot\" or column==\"safety\":\n",
        "    ls = encoder.inverse_transform([0,1,2])\n",
        "  else:\n",
        "    ls = encoder.inverse_transform([0,1,2,3])\n",
        "  for i in range(len(ls)):\n",
        "    print (\"\\t\", i,\":\",ls[i], end=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNgC4unhY5IV"
      },
      "source": [
        "## Building and comparing models with various depths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmHlMeO3DChP"
      },
      "source": [
        "X_train = aug_data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y_train = aug_data[\"target\"]\n",
        "X_test = test_data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y_test = test_data[\"target\"]\n",
        "\n",
        "depth = []\n",
        "gini_train_acc = []\n",
        "gini_test_acc = []\n",
        "cross_train_acc = []\n",
        "cross_test_acc = []\n",
        "gini_train_prec = []\n",
        "gini_test_prec = []\n",
        "cross_train_prec = []\n",
        "cross_test_prec = []\n",
        "gini_train_rec = []\n",
        "gini_test_rec = []\n",
        "cross_train_rec = []\n",
        "cross_test_rec = []\n",
        "gini_train_f1 = []\n",
        "gini_test_f1 = []\n",
        "cross_train_f1 = []\n",
        "cross_test_f1 = []\n",
        "\n",
        "for i in range(3, 30):\n",
        "  depth.append(i)\n",
        "  # Gini split criterion\n",
        "  clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=i, random_state=0)\n",
        "  clf_gini.fit(X_train, Y_train)\n",
        "  y_train = clf_gini.predict(X_train)\n",
        "  y_test = clf_gini.predict(X_test)\n",
        "  gini_train_acc.append(accuracy_score(Y_train, y_train))\n",
        "  gini_test_acc.append(accuracy_score(Y_test, y_test))\n",
        "  gini_train_prec.append(precision_score(Y_train, y_train, average=\"macro\"))\n",
        "  gini_test_prec.append(precision_score(Y_test, y_test, average=\"macro\"))\n",
        "  gini_train_rec.append(recall_score(Y_train, y_train, average=\"macro\"))\n",
        "  gini_test_rec.append(recall_score(Y_test, y_test, average=\"macro\"))\n",
        "  gini_train_f1.append(f1_score(Y_train, y_train, average=\"macro\"))\n",
        "  gini_test_f1.append(f1_score(Y_test, y_test, average=\"macro\"))\n",
        "  # Cross Entropy split criterion\n",
        "  clf_cross = DecisionTreeClassifier(criterion='entropy', max_depth=i, random_state=0)\n",
        "  clf_cross.fit(X_train, Y_train)\n",
        "  y_train = clf_cross.predict(X_train)\n",
        "  y_test = clf_cross.predict(X_test)\n",
        "  cross_train_acc.append(accuracy_score(Y_train, y_train))\n",
        "  cross_test_acc.append(accuracy_score(Y_test, y_test))\n",
        "  cross_train_prec.append(precision_score(Y_train, y_train, average=\"macro\"))\n",
        "  cross_test_prec.append(precision_score(Y_test, y_test, average=\"macro\"))\n",
        "  cross_train_rec.append(recall_score(Y_train, y_train, average=\"macro\"))\n",
        "  cross_test_rec.append(recall_score(Y_test, y_test, average=\"macro\"))\n",
        "  cross_train_f1.append(f1_score(Y_train, y_train, average=\"macro\"))\n",
        "  cross_test_f1.append(f1_score(Y_test, y_test, average=\"macro\"))\n",
        "\n",
        "metrics = {'Depth':depth, 'Gini_Train_Accuracy':gini_train_acc, 'Gini_Test_Accuracy':gini_test_acc, 'Cross_Entropy_Train_Accuracy': cross_train_acc, 'Cross_Entropy_Test_Accuracy': cross_test_acc, \"Gini_Train_Precision\":gini_train_prec, \"Gini_Test_Precision\":gini_test_prec, \"Cross_Entropy_Train_Precision\":cross_train_prec, \"Cross_Entropy_Test_Precision\": cross_test_prec, \"Gini_Train_Recall\":gini_train_rec, \"Gini_Test_Recall\":gini_test_rec, \"Cross_Entropy_Train_Recall\":cross_train_rec, \"Cross_Entropy_Test_Recall\": cross_test_rec, \"Gini_Train_F1\":gini_train_f1, \"Gini_Test_F1\": gini_test_f1, \"Cross_Entropy_Train_F1\":cross_train_f1, \"Cross_Entropy_Test_F1\": cross_test_f1}\n",
        "metrics = pd.DataFrame(metrics)\n",
        "\n",
        "fig, ax = plt.subplots(3,2,figsize=(12,12))\n",
        "metrics.plot(x=\"Depth\", y=[\"Gini_Train_Accuracy\",\"Gini_Test_Accuracy\"], ax=ax[0][0]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Cross_Entropy_Train_Accuracy\", \"Cross_Entropy_Test_Accuracy\"], ax=ax[0][1]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Gini_Train_Precision\",\"Gini_Test_Precision\"], ax=ax[1][0]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Cross_Entropy_Train_Precision\", \"Cross_Entropy_Test_Precision\"], ax=ax[1][1]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Gini_Train_Recall\",\"Gini_Test_Recall\"], ax=ax[1][0]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Cross_Entropy_Train_Recall\", \"Cross_Entropy_Test_Recall\"], ax=ax[1][1]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Gini_Train_F1\",\"Gini_Test_F1\"], ax=ax[2][0]);\n",
        "metrics.plot(x=\"Depth\", y=[\"Cross_Entropy_Train_F1\", \"Cross_Entropy_Test_F1\"], ax=ax[2][1]);"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoBYmA7VZkvR"
      },
      "source": [
        "## Analysing the final selected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfg52v-PM5of"
      },
      "source": [
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=13)\n",
        "clf.fit(X_train, Y_train)\n",
        "y_train = clf.predict(X_train)\n",
        "y_test = clf.predict(X_test)\n",
        "\n",
        "print (\"Training:\")\n",
        "print (\"Accuracy = \", accuracy_score(y_train, Y_train))\n",
        "print (\"Precision = \", precision_score(y_train, Y_train, average=\"macro\"))\n",
        "print (\"Recall = \", recall_score(y_train, Y_train, average=\"macro\"))\n",
        "print (\"F1 Score = \", f1_score(y_train, Y_train, average=\"macro\"))\n",
        "print (\"Test:\")\n",
        "print (\"Accuracy = \", accuracy_score(y_test, Y_test))\n",
        "print (\"Precision = \", precision_score(y_test, Y_test, average=\"macro\"))\n",
        "print (\"Recall = \", recall_score(y_test, Y_test, average=\"macro\"))\n",
        "print (\"F1 Score = \", f1_score(y_test, Y_test, average=\"macro\"))\n",
        "\n",
        "print (classification_report(Y_test, y_test, target_names=[\"acc\",\"good\", \"unacc\",\"vgood\"]))\n",
        "plot_confusion_matrix(clf, X_test, Y_test, display_labels = [\"acc\",\"good\", \"unacc\",\"vgood\"]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSs6J3AuQc2G"
      },
      "source": [
        "# # To plot using dtreeviz\n",
        "# viz = dtreeviz(clf, x_data=X_train, y_data=Y_train, feature_names = [\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"])\n",
        "# viz\n",
        "\n",
        "# # To plot the tree using graphviz\n",
        "# dot_data = tree.export_graphviz(clf, out_file=None, feature_names=[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"], class_names=[\"0\",\"1\",\"2\",\"3\"], filled=True, rounded=True, special_characters=True) \n",
        "# graph = graphviz.Source(dot_data) \n",
        "# graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9qY_1KwZpgO"
      },
      "source": [
        "## Cost complexity pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1BB4pRSaenq"
      },
      "source": [
        "# Post pruning the decision tree\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "\n",
        "# Plotting the total impurities of leaf nodes vs alpha for training set\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "fig, ax = plt.subplots();\n",
        "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\");\n",
        "ax.set_xlabel(\"effective alpha\");\n",
        "ax.set_ylabel(\"total impurity of leaves\");\n",
        "ax.set_title(\"Total Impurity vs effective alpha for training set\");\n",
        "\n",
        "# List of all the classifiers\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    clfs.append(clf)\n",
        "clfs = clfs[:-1]\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "node_counts = [clf.tree_.node_count for clf in clfs]\n",
        "depth = [clf.tree_.max_depth for clf in clfs]\n",
        "fig, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
        "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
        "ax[0].set_xlabel(\"alpha\")\n",
        "ax[0].set_ylabel(\"number of nodes\")\n",
        "ax[0].set_title(\"Number of nodes vs alpha\")\n",
        "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
        "ax[1].set_xlabel(\"alpha\")\n",
        "ax[1].set_ylabel(\"depth of tree\")\n",
        "ax[1].set_title(\"Depth vs alpha\")\n",
        "fig.tight_layout()\n",
        "\n",
        "# Accuracy after post-pruning\n",
        "train_scores = [clf.score(X_train, Y_train) for clf in clfs]\n",
        "test_scores = [clf.score(X_test, Y_test) for clf in clfs]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
        "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}