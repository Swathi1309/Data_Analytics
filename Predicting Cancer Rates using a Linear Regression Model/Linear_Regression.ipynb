{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE4708_Assignment1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSXTTNujGdKuYLorI0CCDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swathi1309/Data_Analytics/blob/main/Predicting%20Cancer%20Rates%20using%20a%20Linear%20Regression%20Model/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5XAj0DQoWCd"
      },
      "source": [
        "# Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5IgPxdPCnz0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import re\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.linear_model as linear_model\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elUTJLRYoZWU"
      },
      "source": [
        "# Functions for data cleaning and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NdYJTXf7rlr"
      },
      "source": [
        "# Functions for data cleaning\n",
        "# To replace a given value in a column with random values in a given range\n",
        "def replace_random(data, column, value, low, high):\n",
        "  for i in range(len(data[column])):\n",
        "    if data.loc[i, column] == value:\n",
        "      data.loc[i, column] = random.randint(low, high)\n",
        "# To remove a regex pattern from the data\n",
        "def remove_pattern(data, column, pattern):\n",
        "  for i in range(len(data[column])):\n",
        "    new = re.sub(pattern, \"\", str(data.loc[i, column]))\n",
        "    data.loc[i, column] = float(new)\n",
        "\n",
        "# Function to plot and save a scatter plot\n",
        "def plot_scatter(data, x, y, c, name):\n",
        "  fig, ax = plt.subplots(figsize=(12,12))\n",
        "  plot = data.plot.scatter(y=y, x=x, c=c,cmap='inferno', ax=ax);\n",
        "  figure = plot.get_figure()\n",
        "  figure.savefig(name, bbox_inches='tight')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuxsY6TjokZn"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TknhVgNIDU_L"
      },
      "source": [
        "# Input data\n",
        "data = pd.read_excel(\"merged_data.xlsx\")\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwGpbGmI1Bme"
      },
      "source": [
        "# Data Cleaning\n",
        "to_drop = ['Unnamed: 0', 'State', 'AreaName', 'fips_x', 'fips_y']\n",
        "data.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "data.replace (to_replace=\"stable\", value=0, inplace = True)\n",
        "data.replace (to_replace=\"falling\", value=-1, inplace=True)\n",
        "data.replace (to_replace=\"rising\", value=1, inplace=True)\n",
        "data.replace (to_replace=\"_\", value=np.nan, inplace = True)\n",
        "data.replace (to_replace=\"__\", value=np.nan, inplace = True)\n",
        "\n",
        "data.replace (to_replace = \"*\", value = np.nan, inplace=True)\n",
        "replace_random(data, 'Avg_Ann_Incidence', '3 or fewer', 0, 3)\n",
        "remove_pattern(data, 'Incidence_Rate', \"#$\")\n",
        "\n",
        "data.set_index('FIPS')\n",
        "\n",
        "data.rename(columns = {'Hispanic':'Med_Income_Hispanic'}, inplace=True)\n",
        "\n",
        "# Normalizing values to the total population\n",
        "data['Poverty_Rate'] = data['All_Poverty']/ (data['All_With'] + data['All_Without'])\n",
        "data['M_Poverty_Rate'] = data['M_Poverty']/ (data['M_With'] + data['M_Without'])\n",
        "data['F_Poverty_Rate'] = data['F_Poverty']/ (data['F_With'] + data['F_Without'])\n",
        "data['M_Ins_Rate'] = data['M_With']/ (data['M_With'] + data['M_Without'])\n",
        "data['F_Ins_Rate'] = data['F_With']/ (data['F_With'] + data['F_Without'])\n",
        "data['All_Ins_Rate'] = data['All_With']/ (data['All_With'] + data['All_Without'])\n",
        "data['Total_Population'] = data['All_With'] + data['All_Without']\n",
        "\n",
        "# Dropping redundant columns\n",
        "to_drop = ['All_Poverty', 'M_Poverty', 'F_Poverty', 'M_With', 'M_Without', 'F_With', 'F_Without', 'All_With', 'All_Without', 'Avg_Ann_Incidence', 'Avg_Ann_Deaths']\n",
        "data.drop(columns=to_drop, inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_zzEdIt-Wh_"
      },
      "source": [
        "# Visualizing missing values\n",
        "# Missing data matrix\n",
        "matrix = msno.matrix(data);\n",
        "matrix_copy = matrix.get_figure()\n",
        "matrix_copy.savefig(\"Missing_data_matrix\", bbox_inches='tight')\n",
        "# Heatmap of correlation between missing values\n",
        "heatmap = msno.heatmap(data);\n",
        "heatmap_copy = heatmap.get_figure()\n",
        "heatmap_copy.savefig(\"Missing_data_heatmap\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkUVRF8yFMbg"
      },
      "source": [
        "# Dropping rows with missing incidence or mortality rates\n",
        "data.dropna(subset=['Incidence_Rate', 'Mortality_Rate'], inplace=True)\n",
        "# Replacing missing data with median, only for Med_Income\n",
        "med_income = data['Med_Income'].median()\n",
        "data['Med_Income'].fillna(value = med_income, inplace=True)\n",
        "# Coverting all data to numeric types (int or float)\n",
        "for column in data:\n",
        "  pd.to_numeric(data[column])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJ9UZTponOl"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A2hsQ1aIeET"
      },
      "source": [
        "# Downloading description of the data\n",
        "description = data.describe()\n",
        "description.to_excel(\"Data_Description.xlsx\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I5XAR0gIg_2"
      },
      "source": [
        "# Downloading correlation matrix\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "corr = sb.heatmap(data.corr(), cmap=\"YlGnBu\", annot=True, ax=ax);\n",
        "corr_copy = corr.get_figure()\n",
        "corr_copy.savefig('Correlation_heatmap',bbox_inches='tight')\n",
        "\n",
        "# Plotting distribution of income by race\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "income_plot = sb.boxplot(data=data[['Med_Income', 'Med_Income_White', 'Med_Income_Black', 'Med_Income_Nat_Am', 'Med_Income_Asian', 'Med_Income_Hispanic']])\n",
        "income_copy = income_plot.get_figure()\n",
        "income_copy.savefig('Income_vs_Race', bbox_inches='tight')\n",
        "\n",
        "# Plotting poverty rates\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "rates_plot = sb.boxplot(data=data[['Poverty_Rate', 'M_Poverty_Rate', 'F_Poverty_Rate', 'All_Ins_Rate', 'M_Ins_Rate', 'F_Ins_Rate']])\n",
        "rates_copy = rates_plot.get_figure()\n",
        "rates_copy.savefig('Poverty_rates', bbox_inches = 'tight')\n",
        "\n",
        "# Plotting incidence and mortality rates\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "rates_plot = sb.boxplot(data=data[['Incidence_Rate', 'Mortality_Rate']])\n",
        "rates_copy = rates_plot.get_figure()\n",
        "rates_copy.savefig('Lung_Cancer_rates', bbox_inches = 'tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJsnWlk86Jvx"
      },
      "source": [
        "# Exploring the relationship between incidence, mortality, and recent trend\n",
        "plot_scatter(data, \"Mortality_Rate\", \"Incidence_Rate\", \"recent_trend\", \"Incidence_vs_Mortality\")\n",
        "\n",
        "# Income vs Incidence plot for each race\n",
        "plot_scatter(data, \"Med_Income\", \"Incidence_Rate\", \"Mortality_Rate\", 'Income_vs_Incidence')\n",
        "plot_scatter(data, \"Med_Income_White\", \"Incidence_Rate\", \"Mortality_Rate\", 'White_Income_vs_Incidence')\n",
        "plot_scatter(data, \"Med_Income_Black\", \"Incidence_Rate\", \"Mortality_Rate\", 'Black_Income_vs_Incidence')\n",
        "plot_scatter(data, \"Med_Income_Nat_Am\", \"Incidence_Rate\", \"Mortality_Rate\", 'Nat_Am_Income_vs_Incidence')\n",
        "plot_scatter(data, \"Med_Income_Asian\", \"Incidence_Rate\", \"Mortality_Rate\", 'Asian_Income_vs_Incidence')\n",
        "plot_scatter(data, \"Med_Income_Hispanic\", \"Incidence_Rate\", \"Mortality_Rate\", 'Hispanic_Income_vs_Incidence')\n",
        "\n",
        "# Relationships between poverty and incidence\n",
        "plot_scatter(data, \"Poverty_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Poverty_vs_Incidence\")\n",
        "plot_scatter(data, \"M_Poverty_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Male_Poverty_vs_Incidence\")\n",
        "plot_scatter(data, \"F_Poverty_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Female_Poverty_vs_Incidence\")\n",
        "\n",
        "# Relationship between insurance rates and incidence\n",
        "# Insurance rate\n",
        "plot_scatter(data, \"All_Ins_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Insurance_vs_Incidence\")\n",
        "plot_scatter(data, \"M_Ins_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Male_Insurance_vs_Incidence\")\n",
        "plot_scatter(data, \"F_Ins_Rate\", \"Incidence_Rate\", \"Mortality_Rate\", \"Female_Insurance_vs_Incidence\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot between uncorrelated features\n",
        "plt = sb.pairplot(data[['Med_Income', 'Poverty_Rate', 'All_Ins_Rate', 'Mortality_Rate', 'Incidence_Rate']]);\n",
        "plt.savefig(\"pairplot.png\")"
      ],
      "metadata": {
        "id": "_VGQKjkYFCqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bslveHvwopad"
      },
      "source": [
        "# Comparing various models to find the best fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXH_juKUr1Im"
      },
      "source": [
        "# Function to compare various models for a given set of input variables and target variable\n",
        "def compare_models(X, Y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size =0.2, random_state=19)\n",
        "  x_train_log = np.log(x_train)\n",
        "  x_test_log = np.log(x_test)\n",
        "\n",
        "  # Linear Regression\n",
        "  print (\"Linear Regression:\")\n",
        "  model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "  model.fit(x_train, y_train)\n",
        "  print (\"Score:\", model.score(x_test, y_test))\n",
        "  print (\"\\n\")\n",
        "\n",
        "  # Linear Regression with Log Transformed Values\n",
        "  print (\"Linear Regression (Log Transformed Values):\")\n",
        "  model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "  model.fit(x_train_log, y_train)\n",
        "  print (\"Score:\", model.score(x_test_log, y_test))\n",
        "  print (\"\\n\")\n",
        "\n",
        "  # Polynomial Regression\n",
        "  print (\"Polynomial Regression:\")\n",
        "  poly = PolynomialFeatures(degree=2)\n",
        "  model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "  model.fit(poly.fit_transform(x_train_log), y_train)\n",
        "  print (\"Score:\", model.score(poly.fit_transform(x_test_log), y_test))\n",
        "  print (\"\\n\")\n",
        "\n",
        "  # Polynomial Regression with Log Transformed Data\n",
        "  print (\"Polynomial Regression (Log Transformed Values):\")\n",
        "  poly = PolynomialFeatures(degree=2)\n",
        "  model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "  model.fit(poly.fit_transform(x_train_log), y_train)\n",
        "  print (\"Score:\", model.score(poly.fit_transform(x_test_log), y_test))\n",
        "  print (\"\\n\")\n",
        "\n",
        "  # Polynomial Regression with Lasso Regularization\n",
        "  print (\"Lasso Regularized Polynomial Regression:\")\n",
        "  poly = PolynomialFeatures(degree=2)\n",
        "  model = make_pipeline(StandardScaler(), linear_model.Lasso(alpha=0.1))\n",
        "  model.fit(poly.fit_transform(x_train_log), y_train)\n",
        "  print (\"Score:\", model.score(poly.fit_transform(x_test_log), y_test))\n",
        "  print (\"\\n\")\n",
        "\n",
        "  # Polynomial Regression with Ridge Regularization\n",
        "  print (\"Ridge Regularized Polynomial Regression:\")\n",
        "  poly = PolynomialFeatures(degree=2)\n",
        "  model = make_pipeline(StandardScaler(), linear_model.Ridge(alpha=0.1))\n",
        "  model.fit(poly.fit_transform(x_train_log), y_train)\n",
        "  print (\"Score:\", model.score(poly.fit_transform(x_test_log), y_test))\n",
        "  print (\"\\n\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2rK_MlIDIqQ",
        "outputId": "cd3cef07-a336-4f5f-aa8b-e93b2d275af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "compare_models(data[['Poverty_Rate','Med_Income','All_Ins_Rate']], data[['Incidence_Rate']])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "Score: 0.21226000694992586\n",
            "\n",
            "\n",
            "Linear Regression (Log Transformed Values):\n",
            "Score: 0.22784843694522994\n",
            "\n",
            "\n",
            "Polynomial Regression:\n",
            "Score: 0.25986150179151124\n",
            "\n",
            "\n",
            "Polynomial Regression (Log Transformed Values):\n",
            "Score: 0.25986150179151124\n",
            "\n",
            "\n",
            "Lasso Regularized Polynomial Regression:\n",
            "Score: 0.22424791265126975\n",
            "\n",
            "\n",
            "Ridge Regularized Polynomial Regression:\n",
            "Score: 0.24551860495186484\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(data[['Poverty_Rate','Med_Income','All_Ins_Rate']], data[['Mortality_Rate']])"
      ],
      "metadata": {
        "id": "-G-mvlaw1qVT",
        "outputId": "9f1fe5b4-bc8f-4311-f3cb-d4459bbc3ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "Score: 0.2642834322328188\n",
            "\n",
            "\n",
            "Linear Regression (Log Transformed Values):\n",
            "Score: 0.28222820616264843\n",
            "\n",
            "\n",
            "Polynomial Regression:\n",
            "Score: 0.308068499518368\n",
            "\n",
            "\n",
            "Polynomial Regression (Log Transformed Values):\n",
            "Score: 0.308068499518368\n",
            "\n",
            "\n",
            "Lasso Regularized Polynomial Regression:\n",
            "Score: 0.27888310797161264\n",
            "\n",
            "\n",
            "Ridge Regularized Polynomial Regression:\n",
            "Score: 0.29506278871120695\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(data[['Poverty_Rate','Med_Income','M_Poverty_Rate','F_Poverty_Rate','M_Ins_Rate','F_Ins_Rate','All_Ins_Rate']], data[['Incidence_Rate']])"
      ],
      "metadata": {
        "id": "_fcujukeyJtF",
        "outputId": "cc46b1f9-e516-4975-d023-1792d5902f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "Score: 0.21232284636821686\n",
            "\n",
            "\n",
            "Linear Regression (Log Transformed Values):\n",
            "Score: 0.22926459260154075\n",
            "\n",
            "\n",
            "Polynomial Regression:\n",
            "Score: 0.2813778778565972\n",
            "\n",
            "\n",
            "Polynomial Regression (Log Transformed Values):\n",
            "Score: 0.2813778778565972\n",
            "\n",
            "\n",
            "Lasso Regularized Polynomial Regression:\n",
            "Score: 0.23362049214526404\n",
            "\n",
            "\n",
            "Ridge Regularized Polynomial Regression:\n",
            "Score: 0.25600353442399215\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models(data[['Poverty_Rate','Med_Income','M_Poverty_Rate','F_Poverty_Rate','M_Ins_Rate','F_Ins_Rate','All_Ins_Rate']], data[['Mortality_Rate']])"
      ],
      "metadata": {
        "id": "YfYxsjgL1pUr",
        "outputId": "915e933a-b2b7-4ccd-970c-71a657f10433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "Score: 0.27035254381033225\n",
            "\n",
            "\n",
            "Linear Regression (Log Transformed Values):\n",
            "Score: 0.2916595901818587\n",
            "\n",
            "\n",
            "Polynomial Regression:\n",
            "Score: 0.3169247098586083\n",
            "\n",
            "\n",
            "Polynomial Regression (Log Transformed Values):\n",
            "Score: 0.3169247098586083\n",
            "\n",
            "\n",
            "Lasso Regularized Polynomial Regression:\n",
            "Score: 0.28871679670098804\n",
            "\n",
            "\n",
            "Ridge Regularized Polynomial Regression:\n",
            "Score: 0.31133072699380937\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}