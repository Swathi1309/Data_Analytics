{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE4703_A5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU3SrTrUil00"
      },
      "source": [
        "# Random Forest to Build a Predictive Model on the Car Evaluation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nAeBO11iwdC"
      },
      "source": [
        "## Importing libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjMuG9UKVxMu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install -U imbalanced-learn\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTEN\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, plot_confusion_matrix, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utp8D4dHiz3k"
      },
      "source": [
        "## Supporting functions to plot various data distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8k5UCYHZrlm"
      },
      "source": [
        "# Plotting the distribution of all features\n",
        "def plot_dist(data):\n",
        "  colors = sns.color_palette('pastel')\n",
        "  print (\"Number of data points = \", data.shape[0])\n",
        "  print (\"Distribution of data points:\")\n",
        "  rows = int(np.ceil(data.shape[1]/4))\n",
        "  fig, ax = plt.subplots(rows, 4, figsize = (12,rows*3))\n",
        "  i = 0\n",
        "  j = 0\n",
        "  for column in data:\n",
        "    counts = pd.DataFrame(data[column].value_counts())\n",
        "    labels = counts.index.values.tolist()\n",
        "    values = data[column].value_counts().tolist()\n",
        "    ax[i][j].pie(values, labels = labels, colors = colors)\n",
        "    ax[i][j].set_title(column)\n",
        "    if j<3:\n",
        "      j += 1\n",
        "    else:\n",
        "      i += 1\n",
        "      j = 0\n",
        "  while j<=3:\n",
        "    ax[i][j].set_axis_off()\n",
        "    j+=1"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUMd0q4ycxpx"
      },
      "source": [
        "# Function to plot input variables pairwise\n",
        "def plot_pairwise(data):\n",
        "  cols = data.columns.tolist()\n",
        "  num = len(cols) - 1\n",
        "  fig, ax = plt.subplots(num, num, figsize = (4*num, 4*num))\n",
        "  for i in range(num):\n",
        "    for j in range(num):\n",
        "      if j<i:\n",
        "        ax[j][i].set_axis_off()\n",
        "      else:\n",
        "        if i==j:\n",
        "          if i==num-1:\n",
        "            sns.histplot(x=cols[i], hue=\"target\", data=data, multiple=\"stack\", palette={\"unacc\":\"skyblue\", \"acc\":\"orange\", \"good\":\"palegreen\", \"vgood\":\"salmon\"}, ax=ax[j][i]);\n",
        "          else:\n",
        "            sns.histplot(x=cols[i], hue=\"target\", data=data, multiple=\"stack\", palette={\"unacc\":\"skyblue\", \"acc\":\"orange\", \"good\":\"palegreen\", \"vgood\":\"salmon\"}, ax=ax[j][i], legend=False);\n",
        "          if j!=num-1:\n",
        "            ax[j][i].set_xlabel(\" \")\n",
        "          if i!=0:\n",
        "            ax[j][i].set_ylabel(\" \")\n",
        "        else:  \n",
        "          df = pd.DataFrame(data.groupby([cols[i], cols[j], \"target\"]).size().reset_index().rename(columns={0:'freq'}))\n",
        "          sns.scatterplot(data=df, x=cols[i], y=cols[j], size=\"freq\", hue=\"target\", sizes=(20, 5000), palette={\"unacc\":\"skyblue\", \"acc\":\"orange\", \"good\":\"palegreen\", \"vgood\":\"salmon\"}, alpha=0.5, legend=False, ax=ax[j][i]);\n",
        "          if j!=num-1:\n",
        "            ax[j][i].set_xlabel(\" \")\n",
        "          if i!=0:\n",
        "            ax[j][i].set_ylabel(\" \")\n",
        "  fig.savefig(\"pairwise\", format=\"svg\", pad_inches=0, bbox_inches =\"tight\")"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwlxn4u-00l"
      },
      "source": [
        "def encode_data(data):\n",
        "  data[\"buying\"].replace(to_replace = [\"low\", \"med\", \"high\", \"vhigh\"], value = [0,1,2,3], inplace=True)\n",
        "  data[\"maint\"].replace(to_replace = [\"low\", \"med\", \"high\", \"vhigh\"], value = [0,1,2,3], inplace=True)\n",
        "  data[\"doors\"].replace(to_replace = [\"2\",\"3\",\"4\",\"5more\"], value = [0,1,2,3], inplace=True)\n",
        "  data[\"persons\"].replace(to_replace = [\"2\",\"4\",\"more\"], value = [0,1,2], inplace=True)\n",
        "  data[\"lug_boot\"].replace(to_replace = [\"small\",\"med\",\"big\"], value = [0,1,2], inplace=True)\n",
        "  data[\"safety\"].replace(to_replace = [\"low\",\"med\",\"high\"], value = [0,1,2], inplace=True)\n",
        "  data[\"target\"].replace(to_replace = [\"unacc\", \"acc\", \"good\", \"vgood\"], value = [0,1,2,3], inplace=True)"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0in3Bwdji5VP"
      },
      "source": [
        "## Reading data, cleaning and visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWLD9ktjZVIw"
      },
      "source": [
        "data = pd.read_csv(\"car_evaluation.csv\")\n",
        "data.columns=[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\", \"target\"]\n",
        "\n",
        "X = data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y = data[\"target\"]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "data = pd.concat([X_train, Y_train], axis=1)\n",
        "test_data = pd.concat([X_test, Y_test], axis=1)\n",
        "\n",
        "# Plotting the distribution of unaugmented training data\n",
        "plot_dist(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNY9IMPcMyo"
      },
      "source": [
        "plot_pairwise(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FaAwAXLtZPE"
      },
      "source": [
        "encode_data(data)\n",
        "encode_data(test_data)"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehil1iHdjBIr"
      },
      "source": [
        "## Building random forest model and tuning hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_v4E4zhuIdM"
      },
      "source": [
        "X = data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y = data[\"target\"]\n",
        "\n",
        "X_test = test_data[[\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]]\n",
        "Y_test = test_data[\"target\"]\n",
        "\n",
        "ensemble_clfs = [(\"Max_features='sqrt'\",RandomForestClassifier(warm_start=True, oob_score=True, max_features=\"sqrt\")),\n",
        "                 (\"Max_features='log2'\",RandomForestClassifier(warm_start=True, max_features=\"log2\", oob_score=True)),\n",
        "                 (\"Max_features=0.5\", RandomForestClassifier(warm_start=True, max_features=0.5, oob_score=True)),\n",
        "                 (\"Max_features=None\", RandomForestClassifier(warm_start=True, max_features=None, oob_score=True))]\n",
        "\n",
        "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
        "accuracy = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
        "f1 = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
        "\n",
        "min_estimators = 5\n",
        "max_estimators = 100\n",
        "\n",
        "for label, clf in ensemble_clfs:\n",
        "    for i in range(min_estimators, max_estimators + 1):\n",
        "        clf.set_params(n_estimators=i)\n",
        "        clf.fit(X, Y)\n",
        "        score = clf.score(X_test, Y_test)\n",
        "        Y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Record the OOB error for each `n_estimators=i` setting.\n",
        "        oob_error = 1 - clf.oob_score_\n",
        "        error_rate[label].append((i, oob_error))\n",
        "        accuracy[label].append((i, score))\n",
        "        f1[label].append((i, f1_score(Y_pred, Y_test, average=\"macro\")))\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize = (20, 15))\n",
        "\n",
        "for label, clf_err in error_rate.items():\n",
        "    x1, y1 = zip(*clf_err)\n",
        "    ax[0][0].plot(x1, y1, label=label);\n",
        "\n",
        "ax[0][0].set_xlabel(\"n_estimators\");\n",
        "ax[0][0].set_ylabel(\"OOB error rate\");\n",
        "ax[0][0].legend(loc=0);\n",
        "\n",
        "for label, clf_err in accuracy.items():\n",
        "    x2, y2 = zip(*clf_err)\n",
        "    ax[1][0].plot(x2, y2, label=label);\n",
        "\n",
        "ax[1][0].set_xlabel(\"n_estimators\");\n",
        "ax[1][0].set_ylabel(\"Accuracy on test data\");\n",
        "ax[1][0].legend(loc=0);\n",
        "\n",
        "for label, clf_err in f1.items():\n",
        "    x3, y3 = zip(*clf_err)\n",
        "    ax[1][1].plot(x3, y3, label=label);\n",
        "\n",
        "ax[1][1].set_xlabel(\"n_estimators\");\n",
        "ax[1][1].set_ylabel(\"F1 score on test data\");\n",
        "ax[1][1].legend(loc=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcJpT_zQjHLg"
      },
      "source": [
        "## Performance of the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMQIjplpPE4W"
      },
      "source": [
        "# Finding performance of the best model on training and test data\n",
        "clf = RandomForestClassifier(warm_start=True, max_features=None, n_estimators=30)\n",
        "clf.fit(X, Y)\n",
        "y_train = clf.predict(X)\n",
        "y_test = clf.predict(X_test)\n",
        "\n",
        "print (\"Training:\")\n",
        "print (\"Accuracy = \", accuracy_score(y_train, Y))\n",
        "print (\"Precision = \", precision_score(y_train, Y, average=\"macro\"))\n",
        "print (\"Recall = \", recall_score(y_train, Y, average=\"macro\"))\n",
        "print (\"F1 Score = \", f1_score(y_train, Y, average=\"macro\"))\n",
        "print (\"Test:\")\n",
        "print (\"Accuracy = \", accuracy_score(y_test, Y_test))\n",
        "print (\"Precision = \", precision_score(y_test, Y_test, average=\"macro\"))\n",
        "print (\"Recall = \", recall_score(y_test, Y_test, average=\"macro\"))\n",
        "print (\"F1 Score = \", f1_score(y_test, Y_test, average=\"macro\"))\n",
        "\n",
        "print (classification_report(Y_test, y_test, target_names=[\"unacc\", \"acc\", \"good\", \"vgood\"]))\n",
        "plot_confusion_matrix(clf, X_test, Y_test, display_labels = [\"unacc\", \"acc\", \"good\", \"vgood\"]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc0OXgJyjRyU"
      },
      "source": [
        "## Variable importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5OcOj45aRkn"
      },
      "source": [
        "values = list(clf.feature_importances_)\n",
        "labels = [\"buying\", \"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\"]\n",
        "\n",
        "plt.bar(labels, values);\n",
        "plt.xlabel(\"Features\");\n",
        "plt.ylabel(\"Variable Importance\");"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
